{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, scipy.stats as stats, matplotlib.pyplot as plt, seaborn as sns, sklearn.preprocessing as prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, RobustScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats.mstats import winsorize\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy z prvej fazy zadania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14908 11039 2592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_product = pd.read_csv(\"product.csv\", sep='\\t')\n",
    "df_session = pd.read_csv(\"session.csv\", sep='\\t')\n",
    "df_users = pd.read_csv(\"user.csv\", sep='\\t')\n",
    "\n",
    "print(len(df_product), len(df_session), len(df_users))\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 17, 20, 21, 22, 25, 26, 28, 31, 32, 33, 37, 38, 39, 41, 43, 44, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 71, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 92, 94, 97, 100, 101, 102, 107, 109, 111, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 136, 138, 139, 140, 141, 144, 145, 148, 149, 151, 152, 153, 154, 155, 156, 160, 162, 163, 164, 165, 166, 168, 169, 174, 175, 176, 177, 182, 184, 186, 187, 190, 191, 192, 194, 196, 198, 202, 205, 206, 207, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 240, 241, 242, 243, 244, 247, 248, 249, 250, 252, 253, 259, 260, 261, 262, 263, 265, 266, 267, 268, 271, 272, 273, 274, 276, 277, 278, 281, 282, 283, 284, 285, 286, 287, 288, 292, 293, 296, 299, 300, 301, 302, 303, 305, 306, 307, 308, 309, 310, 311, 313, 315, 316, 318, 320, 321, 322, 323, 325, 326, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 340, 341, 342, 344, 347, 351, 352, 353, 355, 359, 360, 361, 365, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 382, 385, 386, 387, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 403, 405, 407, 408, 409, 410, 411, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 436, 437, 438, 440, 441, 443, 446, 448, 450, 451, 452, 453, 456, 457, 459, 460, 462, 464, 467, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 482, 484, 485, 488, 489, 492, 496, 500, 501, 503, 505, 508, 513, 514, 515, 518, 519, 520, 521, 522, 523, 526, 527, 529, 530, 531, 532, 534, 535, 537, 539, 540, 541, 543, 546, 548, 549, 550, 551, 552, 553, 555, 556, 557, 558, 559, 561, 562, 564, 565, 566, 568, 572, 576, 577, 578, 579, 580, 584, 587, 590, 594, 595, 598, 599, 600, 601, 604, 608, 610, 612, 613, 615, 616, 618, 619, 620, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 649, 650, 653, 654, 655, 656, 657, 661, 663, 664, 669, 670, 671, 672, 673, 677, 678, 680, 682, 683, 684, 685, 686, 687, 689, 694, 698, 699, 701, 702, 704, 705, 706, 707, 708, 709, 710, 713, 714, 715, 716, 719, 720, 721, 722, 725, 727, 730, 733, 734, 735, 736, 738, 739, 740, 741, 743, 745, 749, 750, 751, 753, 754, 755, 758, 761, 762, 763, 765, 766, 767, 769, 770, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 788, 791, 796, 797, 799, 800, 802, 807, 808, 809, 810, 811, 815, 817, 818, 819, 820, 821, 823, 824, 827, 831, 834, 836, 837, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 852, 853, 854, 855, 856, 860, 861, 862, 864, 865, 866, 867, 869, 876, 877, 878, 879, 880, 881, 882, 884, 886, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 900, 902, 904, 906, 907, 909, 911, 914, 917, 919, 920, 921, 922, 923, 927, 929, 930, 932, 933, 935, 937, 938, 939, 940, 942, 943, 947, 949, 951, 953, 954, 955, 956, 957, 959, 960, 962, 963, 964, 965, 966, 967, 968, 971, 972, 973, 974, 975, 976, 977, 979, 982, 983, 984, 985, 986, 987, 989, 990, 991, 993, 996, 998, 999, 1001, 1002, 1003, 1004, 1007, 1009, 1010, 1012, 1013, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1026, 1029, 1030, 1032, 1034, 1035, 1036, 1038, 1041, 1043, 1044, 1045, 1046, 1047, 1050, 1051, 1052, 1053, 1055, 1056, 1058, 1059, 1060, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1087, 1089, 1090, 1094, 1095, 1096, 1097, 1100, 1102, 1103, 1104, 1105, 1107, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1118, 1119, 1120, 1122, 1123, 1124, 1125, 1127, 1128, 1130, 1131, 1132, 1134, 1136, 1137, 1140, 1143, 1144, 1145, 1147, 1149, 1153, 1155, 1156, 1158, 1159, 1161, 1162, 1163, 1164, 1165, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1179, 1184, 1186, 1187, 1188, 1190, 1191, 1193, 1194, 1196, 1197, 1199, 1201, 1202, 1203, 1204, 1205, 1206, 1208, 1212, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1229, 1230, 1235, 1236, 1238, 1239, 1240, 1242, 1243, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1256, 1257, 1258, 1262, 1264, 1266, 1267, 1269, 1273, 1275, 1277, 1279, 1280, 1281, 1282, 1283, 1285, 1286, 1288, 1290, 1291, 1293, 1294, 1295, 1296, 1298, 1299, 1300, 1303, 1304, 1305, 1306, 1309, 1314, 1315, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1326, 1328, 1330, 1331, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1342, 1343, 1344, 1345, 1346, 1349, 1350, 1352, 1353, 1354, 1355, 1357, 1359, 1361, 1363, 1365, 1366, 1368, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1383, 1384, 1385, 1386, 1387, 1388, 1391, 1392, 1394, 1397, 1398, 1401, 1404, 1406, 1407, 1408, 1410, 1411, 1414, 1415, 1417, 1418, 1419, 1420, 1423, 1428, 1429, 1430, 1433, 1434, 1435, 1436, 1437, 1440, 1441, 1442, 1444, 1445, 1446, 1451, 1454, 1455, 1456, 1458, 1459, 1461, 1463, 1467, 1469, 1471, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1481, 1484, 1485, 1488, 1492, 1494, 1495, 1496, 1498, 1499, 1503, 1504, 1507, 1509, 1510, 1511, 1512, 1514, 1516, 1517, 1519, 1520, 1521, 1522, 1523, 1525, 1527, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1542, 1543, 1544, 1547, 1548, 1549, 1551, 1553, 1556, 1558, 1560, 1561, 1562, 1565, 1567, 1568, 1571, 1573, 1575, 1577, 1578, 1579, 1580, 1581, 1583, 1584, 1585, 1586, 1587, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1611, 1614, 1615, 1616, 1617, 1620, 1625, 1627, 1629, 1630, 1633, 1635, 1636, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1651, 1652, 1656, 1658, 1660, 1662, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1675, 1676, 1678, 1681, 1682, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1704, 1706, 1707, 1708, 1709, 1712, 1715, 1717, 1718, 1719, 1720, 1721, 1723, 1724, 1725, 1726, 1729, 1730, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1742, 1744, 1746, 1747, 1749, 1751, 1753, 1754, 1755, 1756, 1757, 1759, 1763, 1764, 1765, 1766, 1769, 1770, 1771, 1772, 1773, 1774, 1777, 1778, 1780, 1781, 1783, 1784, 1786, 1792, 1796, 1799, 1800, 1802, 1804, 1807, 1808, 1809, 1812, 1813, 1815, 1816, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1831, 1832, 1833, 1839, 1841, 1843, 1844, 1845, 1847, 1851, 1854, 1855, 1856, 1860, 1862, 1865, 1866, 1869, 1872, 1873, 1874, 1875, 1876, 1878, 1879, 1881, 1882, 1883, 1885, 1887, 1889, 1890, 1892, 1893, 1895, 1896, 1897, 1899, 1902, 1903, 1905, 1906, 1907, 1908, 1909, 1911, 1913, 1916, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1931, 1933, 1934, 1937, 1938, 1939, 1940, 1941, 1943, 1944, 1945, 1950, 1953, 1955, 1957, 1958, 1959, 1960, 1961, 1963, 1964, 1965, 1967, 1968, 1969, 1970, 1971, 1972, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1985, 1986, 1989, 1990, 1991, 1994, 1995, 1996, 1997, 1998, 2000, 2001, 2002, 2006, 2011, 2012, 2013, 2014, 2016, 2018, 2021, 2022, 2025, 2026, 2028, 2029, 2032, 2033, 2034, 2035, 2038, 2042, 2044, 2045, 2046, 2047, 2049, 2050, 2052, 2055, 2057, 2058, 2059, 2062, 2063, 2066, 2070, 2074, 2076, 2077, 2078, 2081, 2082, 2083, 2084, 2086, 2087, 2089, 2090, 2093, 2094, 2096, 2097, 2098, 2099, 2100, 2102, 2103, 2105, 2106, 2110, 2113, 2114, 2115, 2118, 2120, 2121, 2122, 2124, 2125, 2126, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2140, 2141, 2142, 2144, 2145, 2146, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2160, 2162, 2163, 2164, 2166, 2167, 2168, 2169, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2179, 2181, 2182, 2186, 2187, 2190, 2191, 2192, 2193, 2194, 2197, 2199, 2201, 2202, 2203, 2204, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2214, 2215, 2216, 2218, 2221, 2224, 2225, 2227, 2229, 2230, 2231, 2232, 2233, 2234, 2238, 2239, 2242, 2243, 2246, 2247, 2250, 2251, 2252, 2254, 2255, 2257, 2258, 2260, 2261, 2262, 2264, 2266, 2268, 2271, 2273, 2274, 2276, 2277, 2281, 2284, 2285, 2286, 2288, 2290, 2291, 2292, 2294, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2309, 2310, 2311, 2313, 2314, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2328, 2330, 2332, 2334, 2335, 2337, 2340, 2341, 2342, 2345, 2348, 2349, 2350, 2351, 2353, 2354, 2356, 2357, 2359, 2361, 2363, 2367, 2368, 2370, 2371, 2372, 2373, 2374, 2378, 2379, 2380, 2381, 2382, 2383, 2385, 2386, 2387, 2388, 2389, 2391, 2392, 2394, 2395, 2397, 2398, 2400, 2401, 2402, 2403, 2404, 2405, 2407, 2410, 2411, 2413, 2414, 2415, 2416, 2417, 2420, 2421, 2422, 2423, 2425, 2426, 2428, 2430, 2431, 2432, 2434, 2437, 2438, 2439, 2440, 2441, 2442, 2444, 2445, 2446, 2447, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2458, 2459, 2460, 2461, 2462, 2464, 2466, 2467, 2468, 2469, 2470, 2472, 2473, 2475, 2476, 2477, 2478, 2479, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2491, 2492, 2493, 2495, 2497, 2498, 2500, 2502, 2504, 2506, 2509, 2510, 2514, 2516, 2519, 2520, 2521, 2522, 2523, 2524, 2527, 2530, 2534, 2535, 2537, 2538, 2539, 2541, 2542, 2544, 2545, 2546, 2547, 2548, 2550, 2551, 2554, 2555, 2558, 2559, 2560, 2561, 2562, 2564, 2565, 2567, 2571, 2572, 2574, 2576, 2577, 2579, 2580, 2582, 2584, 2585, 2586, 2587, 2588, 2589, 2591]\n",
      "2592 949\n"
     ]
    },
    {
     "data": {
      "text/plain": "     index         race         username  sex  \\\n0        1  unspecified    pirescarolina    F   \n1        2          NaN     maskovalucie  NaN   \n2        9          NaN         gda-cruz  NaN   \n3       11          NaN   trommlerleonie    M   \n4       12          NaN      igorcostela  NaN   \n..     ...          ...              ...  ...   \n944   2575          NaN      smithcarmen    M   \n945   2578          NaN          wbarber    M   \n946   2581          NaN        xwatanabe    F   \n947   2583        white  nogueiragabriel  NaN   \n948   2590          NaN         ejelinek    M   \n\n                                             residence  user_id  \\\n0                                                  NaN     2066   \n1                                                  NaN     1023   \n2                                                  NaN     2061   \n3                                                  NaN       96   \n4                                                  NaN     1196   \n..                                                 ...      ...   \n944  564 Andrea Freeway Suite 701\\nWilliamsmouth, N...     1201   \n945                                                NaN     1551   \n946                                                NaN     2093   \n947                                                NaN     2511   \n948                                                NaN     1215   \n\n                     name                                            address  \\\n0           Pietra Castro  Campo de Araújo, 606\\nMonte São José\\n57558095...   \n1      Růžena Pospíšilová                        Kremnická 66\\n518 24 Žacléř   \n2    Emanuel da Conceição                                                NaN   \n3         Leo Hiller-Holt                   Täschering 491\\n69752 Eberswalde   \n4        Beatriz Carvalho  Loteamento Nathan Melo, 8\\nSantana Do Cafezal\\...   \n..                    ...                                                ...   \n944      Keith Patton DDS  04212 Melvin Mountain Suite 359\\nSouth Douglas...   \n945       Eduardo Johnson   408 Davis Junction Apt. 020\\nMejiaside, PA 62823   \n946                 松本 香織         岩手県山武郡九十九里町虎ノ門虎ノ門ヒルズ森タワー4丁目24番12号 ハイツ港南664   \n947        Arthur Cardoso                                                NaN   \n948          Robert Novák       U Nových Domů I 3\\n389 66 Kostelec nad Labem   \n\n                             mail  \\\n0           gomesana@yahoo.com.br   \n1              pavelfiala@post.cz   \n2          gmonteiro@yahoo.com.br   \n3           daniellesontag@gmx.de   \n4    fogacaluiz-otavio@bol.com.br   \n..                            ...   \n944       elizabeth32@hotmail.com   \n945            hvilla@hotmail.com   \n946        yamamotorika@yahoo.com   \n947       correiaalana@bol.com.br   \n948          sonakolarova@post.cz   \n\n                                    current_location          registration  \\\n0    (Decimal('28.1621345'), Decimal('-173.517410'))            2021-08-09   \n1      (Decimal('-80.913702'), Decimal('21.046467'))            2020/08/06   \n2     (Decimal('89.734118'), Decimal('-103.039006'))  11/07/2018, 00:00:00   \n3    (Decimal('-81.5533295'), Decimal('-72.476163'))           12 Jan 2014   \n4     (Decimal('80.7165165'), Decimal('-17.568838'))           25 Nov 2013   \n..                                               ...                   ...   \n944   (Decimal('-70.997122'), Decimal('156.990661'))            2021-01-12   \n945     (Decimal('35.572745'), Decimal('13.032466'))  03/31/2018, 00:00:00   \n946  (Decimal('-12.9191985'), Decimal('-21.733244'))           14 Oct 2013   \n947     (Decimal('-39.812127'), Decimal('0.187696'))  07/05/2022, 00:00:00   \n948  (Decimal('-40.2046775'), Decimal('-54.937258'))            2022/05/04   \n\n      birthdate  \n0           NaN  \n1    1921-09-21  \n2    2000-11-28  \n3    1937-11-17  \n4           NaN  \n..          ...  \n944  1975-01-27  \n945  1951-11-07  \n946  2019-02-17  \n947  1968-08-08  \n948  1943-10-06  \n\n[949 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>race</th>\n      <th>username</th>\n      <th>sex</th>\n      <th>residence</th>\n      <th>user_id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>mail</th>\n      <th>current_location</th>\n      <th>registration</th>\n      <th>birthdate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>unspecified</td>\n      <td>pirescarolina</td>\n      <td>F</td>\n      <td>NaN</td>\n      <td>2066</td>\n      <td>Pietra Castro</td>\n      <td>Campo de Araújo, 606\\nMonte São José\\n57558095...</td>\n      <td>gomesana@yahoo.com.br</td>\n      <td>(Decimal('28.1621345'), Decimal('-173.517410'))</td>\n      <td>2021-08-09</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>maskovalucie</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1023</td>\n      <td>Růžena Pospíšilová</td>\n      <td>Kremnická 66\\n518 24 Žacléř</td>\n      <td>pavelfiala@post.cz</td>\n      <td>(Decimal('-80.913702'), Decimal('21.046467'))</td>\n      <td>2020/08/06</td>\n      <td>1921-09-21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>gda-cruz</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2061</td>\n      <td>Emanuel da Conceição</td>\n      <td>NaN</td>\n      <td>gmonteiro@yahoo.com.br</td>\n      <td>(Decimal('89.734118'), Decimal('-103.039006'))</td>\n      <td>11/07/2018, 00:00:00</td>\n      <td>2000-11-28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>trommlerleonie</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>96</td>\n      <td>Leo Hiller-Holt</td>\n      <td>Täschering 491\\n69752 Eberswalde</td>\n      <td>daniellesontag@gmx.de</td>\n      <td>(Decimal('-81.5533295'), Decimal('-72.476163'))</td>\n      <td>12 Jan 2014</td>\n      <td>1937-11-17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>NaN</td>\n      <td>igorcostela</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1196</td>\n      <td>Beatriz Carvalho</td>\n      <td>Loteamento Nathan Melo, 8\\nSantana Do Cafezal\\...</td>\n      <td>fogacaluiz-otavio@bol.com.br</td>\n      <td>(Decimal('80.7165165'), Decimal('-17.568838'))</td>\n      <td>25 Nov 2013</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>944</th>\n      <td>2575</td>\n      <td>NaN</td>\n      <td>smithcarmen</td>\n      <td>M</td>\n      <td>564 Andrea Freeway Suite 701\\nWilliamsmouth, N...</td>\n      <td>1201</td>\n      <td>Keith Patton DDS</td>\n      <td>04212 Melvin Mountain Suite 359\\nSouth Douglas...</td>\n      <td>elizabeth32@hotmail.com</td>\n      <td>(Decimal('-70.997122'), Decimal('156.990661'))</td>\n      <td>2021-01-12</td>\n      <td>1975-01-27</td>\n    </tr>\n    <tr>\n      <th>945</th>\n      <td>2578</td>\n      <td>NaN</td>\n      <td>wbarber</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>1551</td>\n      <td>Eduardo Johnson</td>\n      <td>408 Davis Junction Apt. 020\\nMejiaside, PA 62823</td>\n      <td>hvilla@hotmail.com</td>\n      <td>(Decimal('35.572745'), Decimal('13.032466'))</td>\n      <td>03/31/2018, 00:00:00</td>\n      <td>1951-11-07</td>\n    </tr>\n    <tr>\n      <th>946</th>\n      <td>2581</td>\n      <td>NaN</td>\n      <td>xwatanabe</td>\n      <td>F</td>\n      <td>NaN</td>\n      <td>2093</td>\n      <td>松本 香織</td>\n      <td>岩手県山武郡九十九里町虎ノ門虎ノ門ヒルズ森タワー4丁目24番12号 ハイツ港南664</td>\n      <td>yamamotorika@yahoo.com</td>\n      <td>(Decimal('-12.9191985'), Decimal('-21.733244'))</td>\n      <td>14 Oct 2013</td>\n      <td>2019-02-17</td>\n    </tr>\n    <tr>\n      <th>947</th>\n      <td>2583</td>\n      <td>white</td>\n      <td>nogueiragabriel</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2511</td>\n      <td>Arthur Cardoso</td>\n      <td>NaN</td>\n      <td>correiaalana@bol.com.br</td>\n      <td>(Decimal('-39.812127'), Decimal('0.187696'))</td>\n      <td>07/05/2022, 00:00:00</td>\n      <td>1968-08-08</td>\n    </tr>\n    <tr>\n      <th>948</th>\n      <td>2590</td>\n      <td>NaN</td>\n      <td>ejelinek</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>1215</td>\n      <td>Robert Novák</td>\n      <td>U Nových Domů I 3\\n389 66 Kostelec nad Labem</td>\n      <td>sonakolarova@post.cz</td>\n      <td>(Decimal('-40.2046775'), Decimal('-54.937258'))</td>\n      <td>2022/05/04</td>\n      <td>1943-10-06</td>\n    </tr>\n  </tbody>\n</table>\n<p>949 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodupuser = df_users\n",
    "idecka = {}\n",
    "for id in df_users[\"user_id\"]:\n",
    "    if id in idecka.keys():\n",
    "        idecka[id] += 1\n",
    "    else:\n",
    "        idecka[id] = 1\n",
    "to_remove = []\n",
    "for row in df_users.iterrows():\n",
    "    index = row[0]\n",
    "    user_id = row[1][\"user_id\"]\n",
    "    if idecka[user_id] > 1:\n",
    "        to_remove.append(index)\n",
    "print(to_remove)\n",
    "df_nodupuser = df_nodupuser.drop(to_remove)\n",
    "print(len(df_users), len(df_nodupuser))\n",
    "df_nodupuser.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      session_id  session_duration  pct_mouse_click  pct_mouse_move  \\\n0         223045          47.96486         11.32534        11.29606   \n1         623734         132.25714         11.88174        11.58618   \n2         159057         143.60687          7.83379         2.92107   \n3         551040         248.09308          4.95972         4.52411   \n4           6355         165.90198         11.27945        14.79490   \n...          ...               ...              ...             ...   \n4070      817978         168.30985         13.22728        13.23870   \n4071      992036         172.54963         11.39298        14.91608   \n4072      856525          92.97564          9.92790         7.32274   \n4073      472623          54.60196         10.88118        11.77482   \n4074       88768         158.27488         10.70147        11.07255   \n\n      pct_scrandom browser_name  pct_scroll_move  wild_mouse_duration  \\\n0         48.47653      firefox         48.95236             11.39144   \n1         25.58663       safari         51.07750              9.44179   \n2         70.63719        opera         41.89119             10.05044   \n3         48.16995        opera         54.76994              9.96582   \n4         49.78113       chrome         44.72991              8.48023   \n...            ...          ...              ...                  ...   \n4070      59.44815         edge         43.64091             11.70369   \n4071      41.20110         edge         47.24597              9.50976   \n4072      59.13477       chrome         58.16094             10.43395   \n4073      44.68072       chrome         57.48251              7.80662   \n4074      60.81757       chrome         60.49513              8.79697   \n\n      total_load_time screen_width  ...         race          username  sex  \\\n0             2.30071         1280  ...        black         gscalfaro  NaN   \n1             1.84508        lower  ...        black         gscalfaro  NaN   \n2             2.92902        lower  ...        black         gscalfaro  NaN   \n3             8.07877         1366  ...        black         gscalfaro  NaN   \n4             2.04936          800  ...        black         gscalfaro  NaN   \n...               ...          ...  ...          ...               ...  ...   \n4070          1.05211         1280  ...        asian            ccerna    M   \n4071          2.63677       higher  ...          NaN  agnolosanguineti  NaN   \n4072          5.45315          800  ...          NaN          milena14    F   \n4073          4.27341         1280  ...          NaN          milena14    F   \n4074          7.33300          800  ...  unspecified           donna07    F   \n\n                       residence                   name  \\\n0                            NaN          Gianni Sagese   \n1                            NaN          Gianni Sagese   \n2                            NaN          Gianni Sagese   \n3                            NaN          Gianni Sagese   \n4                            NaN          Gianni Sagese   \n...                          ...                    ...   \n4070  Pyšelská 1\\n369 25 Žamberk         Miloslav Dušek   \n4071                         NaN  Sig. Micheletto Dalla   \n4072                         NaN          Bianca Fogaça   \n4073                         NaN          Bianca Fogaça   \n4074                         NaN    Angelica Berlusconi   \n\n                                                address  \\\n0     Piazza Silvio, 97 Appartamento 98\\n67058, San ...   \n1     Piazza Silvio, 97 Appartamento 98\\n67058, San ...   \n2     Piazza Silvio, 97 Appartamento 98\\n67058, San ...   \n3     Piazza Silvio, 97 Appartamento 98\\n67058, San ...   \n4     Piazza Silvio, 97 Appartamento 98\\n67058, San ...   \n...                                                 ...   \n4070                                                NaN   \n4071  Contrada Roman, 975 Appartamento 5\\n00127, Mez...   \n4072                                                NaN   \n4073                                                NaN   \n4074  Via Baglioni, 82 Piano 5\\n30028, Pozzi San Mic...   \n\n                             mail  \\\n0      arturocostalonga@libero.it   \n1      arturocostalonga@libero.it   \n2      arturocostalonga@libero.it   \n3      arturocostalonga@libero.it   \n4      arturocostalonga@libero.it   \n...                           ...   \n4070  krejcovabohumila@centrum.cz   \n4071           paloma99@gmail.com   \n4072       sarahcardoso@ig.com.br   \n4073       sarahcardoso@ig.com.br   \n4074     romanapisaroni@yahoo.com   \n\n                                    current_location          registration  \\\n0     (Decimal('-72.364280'), Decimal('101.224035'))            2021-09-11   \n1     (Decimal('-72.364280'), Decimal('101.224035'))            2021-09-11   \n2     (Decimal('-72.364280'), Decimal('101.224035'))            2021-09-11   \n3     (Decimal('-72.364280'), Decimal('101.224035'))            2021-09-11   \n4     (Decimal('-72.364280'), Decimal('101.224035'))            2021-09-11   \n...                                              ...                   ...   \n4070  (Decimal('39.6622325'), Decimal('-62.817658'))  12/10/2021, 00:00:00   \n4071  (Decimal('73.519198'), Decimal('-116.041196'))  03/16/2017, 00:00:00   \n4072  (Decimal('89.4235045'), Decimal('-41.293519'))            2018-06-20   \n4073  (Decimal('89.4235045'), Decimal('-41.293519'))            2018-06-20   \n4074   (Decimal('69.456524'), Decimal('-99.261266'))           04 May 2022   \n\n       birthdate  \n0     1938-10-26  \n1     1938-10-26  \n2     1938-10-26  \n3     1938-10-26  \n4     1938-10-26  \n...          ...  \n4070  1964-12-12  \n4071  1965-11-23  \n4072  2006-09-19  \n4073  2006-09-19  \n4074  1923-10-26  \n\n[4075 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session_id</th>\n      <th>session_duration</th>\n      <th>pct_mouse_click</th>\n      <th>pct_mouse_move</th>\n      <th>pct_scrandom</th>\n      <th>browser_name</th>\n      <th>pct_scroll_move</th>\n      <th>wild_mouse_duration</th>\n      <th>total_load_time</th>\n      <th>screen_width</th>\n      <th>...</th>\n      <th>race</th>\n      <th>username</th>\n      <th>sex</th>\n      <th>residence</th>\n      <th>name</th>\n      <th>address</th>\n      <th>mail</th>\n      <th>current_location</th>\n      <th>registration</th>\n      <th>birthdate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>223045</td>\n      <td>47.96486</td>\n      <td>11.32534</td>\n      <td>11.29606</td>\n      <td>48.47653</td>\n      <td>firefox</td>\n      <td>48.95236</td>\n      <td>11.39144</td>\n      <td>2.30071</td>\n      <td>1280</td>\n      <td>...</td>\n      <td>black</td>\n      <td>gscalfaro</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gianni Sagese</td>\n      <td>Piazza Silvio, 97 Appartamento 98\\n67058, San ...</td>\n      <td>arturocostalonga@libero.it</td>\n      <td>(Decimal('-72.364280'), Decimal('101.224035'))</td>\n      <td>2021-09-11</td>\n      <td>1938-10-26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>623734</td>\n      <td>132.25714</td>\n      <td>11.88174</td>\n      <td>11.58618</td>\n      <td>25.58663</td>\n      <td>safari</td>\n      <td>51.07750</td>\n      <td>9.44179</td>\n      <td>1.84508</td>\n      <td>lower</td>\n      <td>...</td>\n      <td>black</td>\n      <td>gscalfaro</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gianni Sagese</td>\n      <td>Piazza Silvio, 97 Appartamento 98\\n67058, San ...</td>\n      <td>arturocostalonga@libero.it</td>\n      <td>(Decimal('-72.364280'), Decimal('101.224035'))</td>\n      <td>2021-09-11</td>\n      <td>1938-10-26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>159057</td>\n      <td>143.60687</td>\n      <td>7.83379</td>\n      <td>2.92107</td>\n      <td>70.63719</td>\n      <td>opera</td>\n      <td>41.89119</td>\n      <td>10.05044</td>\n      <td>2.92902</td>\n      <td>lower</td>\n      <td>...</td>\n      <td>black</td>\n      <td>gscalfaro</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gianni Sagese</td>\n      <td>Piazza Silvio, 97 Appartamento 98\\n67058, San ...</td>\n      <td>arturocostalonga@libero.it</td>\n      <td>(Decimal('-72.364280'), Decimal('101.224035'))</td>\n      <td>2021-09-11</td>\n      <td>1938-10-26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>551040</td>\n      <td>248.09308</td>\n      <td>4.95972</td>\n      <td>4.52411</td>\n      <td>48.16995</td>\n      <td>opera</td>\n      <td>54.76994</td>\n      <td>9.96582</td>\n      <td>8.07877</td>\n      <td>1366</td>\n      <td>...</td>\n      <td>black</td>\n      <td>gscalfaro</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gianni Sagese</td>\n      <td>Piazza Silvio, 97 Appartamento 98\\n67058, San ...</td>\n      <td>arturocostalonga@libero.it</td>\n      <td>(Decimal('-72.364280'), Decimal('101.224035'))</td>\n      <td>2021-09-11</td>\n      <td>1938-10-26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6355</td>\n      <td>165.90198</td>\n      <td>11.27945</td>\n      <td>14.79490</td>\n      <td>49.78113</td>\n      <td>chrome</td>\n      <td>44.72991</td>\n      <td>8.48023</td>\n      <td>2.04936</td>\n      <td>800</td>\n      <td>...</td>\n      <td>black</td>\n      <td>gscalfaro</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gianni Sagese</td>\n      <td>Piazza Silvio, 97 Appartamento 98\\n67058, San ...</td>\n      <td>arturocostalonga@libero.it</td>\n      <td>(Decimal('-72.364280'), Decimal('101.224035'))</td>\n      <td>2021-09-11</td>\n      <td>1938-10-26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4070</th>\n      <td>817978</td>\n      <td>168.30985</td>\n      <td>13.22728</td>\n      <td>13.23870</td>\n      <td>59.44815</td>\n      <td>edge</td>\n      <td>43.64091</td>\n      <td>11.70369</td>\n      <td>1.05211</td>\n      <td>1280</td>\n      <td>...</td>\n      <td>asian</td>\n      <td>ccerna</td>\n      <td>M</td>\n      <td>Pyšelská 1\\n369 25 Žamberk</td>\n      <td>Miloslav Dušek</td>\n      <td>NaN</td>\n      <td>krejcovabohumila@centrum.cz</td>\n      <td>(Decimal('39.6622325'), Decimal('-62.817658'))</td>\n      <td>12/10/2021, 00:00:00</td>\n      <td>1964-12-12</td>\n    </tr>\n    <tr>\n      <th>4071</th>\n      <td>992036</td>\n      <td>172.54963</td>\n      <td>11.39298</td>\n      <td>14.91608</td>\n      <td>41.20110</td>\n      <td>edge</td>\n      <td>47.24597</td>\n      <td>9.50976</td>\n      <td>2.63677</td>\n      <td>higher</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>agnolosanguineti</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Sig. Micheletto Dalla</td>\n      <td>Contrada Roman, 975 Appartamento 5\\n00127, Mez...</td>\n      <td>paloma99@gmail.com</td>\n      <td>(Decimal('73.519198'), Decimal('-116.041196'))</td>\n      <td>03/16/2017, 00:00:00</td>\n      <td>1965-11-23</td>\n    </tr>\n    <tr>\n      <th>4072</th>\n      <td>856525</td>\n      <td>92.97564</td>\n      <td>9.92790</td>\n      <td>7.32274</td>\n      <td>59.13477</td>\n      <td>chrome</td>\n      <td>58.16094</td>\n      <td>10.43395</td>\n      <td>5.45315</td>\n      <td>800</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>milena14</td>\n      <td>F</td>\n      <td>NaN</td>\n      <td>Bianca Fogaça</td>\n      <td>NaN</td>\n      <td>sarahcardoso@ig.com.br</td>\n      <td>(Decimal('89.4235045'), Decimal('-41.293519'))</td>\n      <td>2018-06-20</td>\n      <td>2006-09-19</td>\n    </tr>\n    <tr>\n      <th>4073</th>\n      <td>472623</td>\n      <td>54.60196</td>\n      <td>10.88118</td>\n      <td>11.77482</td>\n      <td>44.68072</td>\n      <td>chrome</td>\n      <td>57.48251</td>\n      <td>7.80662</td>\n      <td>4.27341</td>\n      <td>1280</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>milena14</td>\n      <td>F</td>\n      <td>NaN</td>\n      <td>Bianca Fogaça</td>\n      <td>NaN</td>\n      <td>sarahcardoso@ig.com.br</td>\n      <td>(Decimal('89.4235045'), Decimal('-41.293519'))</td>\n      <td>2018-06-20</td>\n      <td>2006-09-19</td>\n    </tr>\n    <tr>\n      <th>4074</th>\n      <td>88768</td>\n      <td>158.27488</td>\n      <td>10.70147</td>\n      <td>11.07255</td>\n      <td>60.81757</td>\n      <td>chrome</td>\n      <td>60.49513</td>\n      <td>8.79697</td>\n      <td>7.33300</td>\n      <td>800</td>\n      <td>...</td>\n      <td>unspecified</td>\n      <td>donna07</td>\n      <td>F</td>\n      <td>NaN</td>\n      <td>Angelica Berlusconi</td>\n      <td>Via Baglioni, 82 Piano 5\\n30028, Pozzi San Mic...</td>\n      <td>romanapisaroni@yahoo.com</td>\n      <td>(Decimal('69.456524'), Decimal('-99.261266'))</td>\n      <td>04 May 2022</td>\n      <td>1923-10-26</td>\n    </tr>\n  </tbody>\n</table>\n<p>4075 rows × 35 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_session.merge(df_nodupuser, how=\"inner\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rrrr-mm-dd\n",
    "# rrrr/mm/dd\n",
    "# mm/dd/rrrr, 00:00:00\n",
    "# dd Mes rrrr\n",
    "\n",
    "def get_format(date):\n",
    "    months = {\n",
    "        \"Jan\": 1,\n",
    "        \"Feb\": 2,\n",
    "        \"Mar\": 3,\n",
    "        \"Apr\": 4,\n",
    "        \"May\": 5,\n",
    "        \"Jun\": 6,\n",
    "        \"Jul\": 7,\n",
    "        \"Aug\": 8,\n",
    "        \"Sep\": 9,\n",
    "        \"Oct\": 10,\n",
    "        \"Nov\": 11,\n",
    "        \"Dec\": 12\n",
    "    }\n",
    "    if len(date.split(\"-\")) == 3:\n",
    "        splitted = date.split(\"-\")\n",
    "        rok = splitted[0]\n",
    "        mesiac = splitted[1]\n",
    "        den = splitted[2]\n",
    "    elif len(date.split(\"/\")) == 3:\n",
    "        splitted = date.split(\"/\")\n",
    "        if len(splitted[2]) > 4:\n",
    "            mesiac = splitted[0]\n",
    "            den = splitted[1]\n",
    "            rok = splitted[2][:4]\n",
    "        else:\n",
    "            rok = splitted[0]\n",
    "            mesiac = splitted[1]\n",
    "            den = splitted[2]\n",
    "    elif len(date.split(\" \")) == 3:\n",
    "        splitted = date.split(\" \")\n",
    "        den = splitted[0]\n",
    "        mesiac = months[splitted[1]]\n",
    "        rok = splitted[2]\n",
    "    return f\"{rok}-{mesiac}-{den}\"\n",
    "\n",
    "\n",
    "for row in df_merged.iterrows():\n",
    "    datum = get_format(row[1][\"registration\"])\n",
    "    df_merged.at[row[0], \"registration\"] = datum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. faza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation\n",
    "- premena session_start na sekudy od epochu_startu pre numerickost dat\n",
    "- a zmena registracie na ciselnu hodnotu zmenou z 2018-08-12 na 20180812 co znamena ze vacsi datum je aj numericky vacsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def to_seconds_since_epoch(date_str):\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S\"  # Adjust this format to match the format in your DataFrame\n",
    "    date = datetime.strptime(date_str, date_format)\n",
    "    epoch_start = datetime(1970, 1, 1)\n",
    "    return (date - epoch_start).total_seconds()\n",
    "\n",
    "\n",
    "def to_int_from_registration(regtistration):\n",
    "    return int(''.join(regtistration.split(\"-\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vymazavanie dat podla pomeru NaN hodnot\n",
    "- ak je pomer NaN vacsi ako zvoleny percentage stlpec sa vymaze\n",
    "- taktiez sa vymazavaju stlpce s identifikacnymi hodnotami ako napr session_id, user_id, product_ean\n",
    "- zaroven sa vymazavaju string stlpce, ktore maju vysoku diverzitu a zaroven nemaju vela spolocneho s predikovanim vysledku (bohuzial aj current location kedze je nahodne vygenerovana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def NaN_pomer_del(df, percentage):\n",
    "    ratio = int(((100 - percentage) / 100) * df.shape[0] + 1)\n",
    "    nan_percentage = df.isna().mean() * 100\n",
    "    print(\"deleted rows:\\n\", nan_percentage[nan_percentage > 30])\n",
    "    df = df.dropna(axis=1, thresh=ratio)\n",
    "    df = df.drop(\n",
    "        columns=['session_id', 'user_id', 'product_ean', 'name', 'username', 'address', 'mail', 'current_location'],\n",
    "        axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Integrácia a čistenie dát\n",
    "#### odstránenie pozorovaní s chýbajúcimi údajmi\n",
    "\n",
    "#### nahradenie chýbajúcej hodnoty priemerom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_missing_rows(df):\n",
    "    df = df_merged.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_missing_All(df):\n",
    "    \"\"\"\n",
    "    :param df: dataframe\n",
    "    :return: dataframe with replaced empty values of numerical columns with average of that column\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "\n",
    "            mean_value = df[column].mean()\n",
    "            df[column].fillna(mean_value, inplace=True)\n",
    "        elif not pd.api.types.is_numeric_dtype(df[column]):\n",
    "            df[column].fillna('unspecified', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Integrácia a čistenie dát\n",
    "#### odstránenie vychýlených (odľahlých) pozorovaní\n",
    "- odstrániť údaje je vhodné napríklad, ak je session_duration príliš veľké alebo malé.\n",
    "#### nahradenie vychýlenej hodnoty hraničnými hodnotami rozdelenia (napr. 5%, 95%)\n",
    "- nahradenie outlierov meanom daného stĺpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_outliers_for_num_column(df, bottom, top, all=False, column_names=None):\n",
    "    \"\"\"\n",
    "    :param df: dataframe\n",
    "    :param column_names: list/tuple of columns to process\n",
    "    :param bottom: lower quantile bound, 0-1\n",
    "    :param top: upper quantile bound, 0-1\n",
    "    :param all: True if this should be done for all columns\n",
    "    :return: dataframe without outliers\n",
    "    \"\"\"\n",
    "    if all:\n",
    "        for column in df.select_dtypes(include=['number']):\n",
    "            lower_percentile = df[column].quantile(bottom)\n",
    "            upper_percentile = df[column].quantile(top)\n",
    "\n",
    "            df_cleaned = df[(df[column] >= lower_percentile) & (df[column] <= upper_percentile)].dropna()\n",
    "    else:\n",
    "        for column in df:\n",
    "            if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "                continue\n",
    "            lower_percentile = df[column].quantile(bottom)\n",
    "            upper_percentile = df[column].quantile(top)\n",
    "\n",
    "            df_cleaned = df[(df[column] >= lower_percentile) & (df[column] <= upper_percentile)].dropna()\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def replace_outliers_for_num_column(df, bottom, top, all=False, column_names=None):\n",
    "    \"\"\"\n",
    "    :param df: dataframe\n",
    "    :param column_names: list/tuple of columns to process\n",
    "    :param bottom: lower quantile bound, 0-1\n",
    "    :param top: upper quantile bound, 0-1\n",
    "    :param all: True if this should be done for all columns\n",
    "    :return: dataframe with replaced outliers\n",
    "    \"\"\"\n",
    "    if all:\n",
    "        for column in df.select_dtypes(include='number').columns:\n",
    "            lower_threshold = df[column].quantile(bottom)\n",
    "            upper_threshold = df[column].quantile(top)\n",
    "\n",
    "            df[column] = df[column].apply(\n",
    "                lambda x: lower_threshold if x < lower_threshold else (upper_threshold if x > upper_threshold else x))\n",
    "\n",
    "    else:\n",
    "        for column in df:\n",
    "\n",
    "            if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "                continue\n",
    "            lower_threshold = df[column].quantile(bottom)\n",
    "            upper_threshold = df[column].quantile(top)\n",
    "\n",
    "            df[column] = df[column].apply(\n",
    "                lambda x: lower_threshold if x < lower_threshold else (upper_threshold if x > upper_threshold else x))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizacia predspracovania dat\n",
    "\n",
    "### Transformers a Scalers\n",
    "- po testovani 5 transformerov nam vysli boxcox a pow_one_point_two ako 2 najlepsie transformery a tak vyuzivame tie\n",
    "- pre scalery pouzivame na porovnanie MinMaxScaler, StandardScaler a RobustScaler (implementovany az pri pipeline)\n",
    "    - funkcie nizsie su tu len pre rozdelenie a strukturovanie odovzdania kedze su nasledne prepisane aby fungovali ako class pre pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qq_compare(df, column):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    stats.probplot(df[column], dist='norm', plot=plt)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(df[column])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def box_cox_transf(df, column):\n",
    "    boxcox_t = pd.DataFrame(df[column])\n",
    "    boxcox_t[column], param = stats.boxcox(boxcox_t[column])\n",
    "\n",
    "    return [boxcox_t, param]\n",
    "\n",
    "\n",
    "def pow_pointtwo_t(df, column):\n",
    "    pow_pointtwo_t = pd.DataFrame((df[column]) ** (1 / 1.2))\n",
    "    return pow_pointtwo_t\n",
    "\n",
    "\n",
    "def standard_scaler(type, df):\n",
    "    stand_scaler = StandardScaler()\n",
    "    if type == 'train':\n",
    "        df_scaled = stand_scaler.fit_transform(df)\n",
    "    else:\n",
    "        df_scaled = stand_scaler.transform(df)\n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "def min_max_scaler(type, df):\n",
    "    min_max = MinMaxScaler()\n",
    "    if type == 'train':\n",
    "        df_scaled = min_max.fit_transform(df)\n",
    "    else:\n",
    "        df_scaled = min_max.transform(df)\n",
    "    return df_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 sposoby feature selection\n",
    "- SelectKBest so skorovaciou funckiou f_classif - pouzita pretoze je dobra na klasifikovanie numerickych atributov co je vacsina nasich atributov\n",
    "- Select podla korelacie s predikovanou premennou na porovnanie\n",
    "- SelectKBest so skorovaciou funkciou chi-squared - pouzita len na porovnanie kedze chi squared vyzaduje pozitivne cisla, moze sa teda pouzit len zaroven s MinMaxScalerom pretoze ostatne scalery vytvoria aj negativne hodnoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_best_classif(df, ack_df, n):\n",
    "    best_feat = SelectKBest(score_func=f_classif, k=n)\n",
    "    fit = best_feat.fit(df, ack_df)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(df.columns)\n",
    "    feature_scores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    feature_scores.columns = [\"feature\", \"score\"]\n",
    "    print(feature_scores.sort_values('score', ascending=False).nlargest(10, 'score'))\n",
    "\n",
    "\n",
    "def K_best_chi2(df, ack_df, n):\n",
    "    best_feat = SelectKBest(score_func=chi2, k=n)\n",
    "    fit = best_feat.fit(df, ack_df)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(df.columns)\n",
    "    feature_scores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    feature_scores.columns = [\"feature\", \"score\"]\n",
    "    print(feature_scores.sort_values('score', ascending=False).nlargest(10, 'score'))\n",
    "\n",
    "\n",
    "def corr_best(df, k):\n",
    "    corr_max = abs(df.corr())\n",
    "    print(corr_max['ack'].nlargest(k))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vytvorenie pipeline\n",
    "- vyuzity sklearn.pipeline\n",
    "- kazda trieda predstavuje jeden krok pipeline\n",
    "- zostavovanie pipeline je modularne co znamena ze sa napr. rozne transformery sa mozu  zamienat iba zmenou nazvu triedy v pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted rows:\n",
      " race         70.552147\n",
      "sex          49.055215\n",
      "residence    63.411043\n",
      "birthdate    46.061350\n",
      "dtype: float64\n",
      "                   feature       score\n",
      "1          pct_mouse_click  602.705958\n",
      "12         pct_doubleclick  596.707260\n",
      "15  page_activity_duration  542.650179\n",
      "2           pct_mouse_move  188.909235\n",
      "29                  1920_W    6.988940\n",
      "18            registration    5.068868\n",
      "9   pct_click_product_info    3.913190\n",
      "4          pct_scroll_move    3.553247\n",
      "26                  1024_W    2.810677\n",
      "0         session_duration    2.541455\n",
      "-------------------\n",
      "ack                       1.000000\n",
      "pct_mouse_click           0.395111\n",
      "pct_doubleclick           0.393446\n",
      "page_activity_duration    0.377860\n",
      "pct_mouse_move            0.234106\n",
      "1920_W                    0.046266\n",
      "registration              0.039413\n",
      "pct_click_product_info    0.034636\n",
      "pct_scroll_move           0.033007\n",
      "1024_W                    0.029359\n",
      "Name: ack, dtype: float64\n",
      "                     feature       score\n",
      "12           pct_doubleclick  171.072875\n",
      "1            pct_mouse_click  155.514443\n",
      "15    page_activity_duration  106.473722\n",
      "2             pct_mouse_move   31.403131\n",
      "11            pct_wild_mouse    7.038924\n",
      "0           session_duration    7.007970\n",
      "21                   firefox    4.730283\n",
      "17             session_start    4.268318\n",
      "13                 pct_input    4.248374\n",
      "10  pct_scroll_move_duration    3.908624\n",
      "-------------------\n",
      "ack                       1.000000\n",
      "pct_doubleclick           0.416943\n",
      "pct_mouse_click           0.400712\n",
      "page_activity_duration    0.340292\n",
      "pct_mouse_move            0.192846\n",
      "pct_wild_mouse            0.092648\n",
      "session_duration          0.092446\n",
      "firefox                   0.076057\n",
      "session_start             0.072268\n",
      "pct_input                 0.072100\n",
      "Name: ack, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def split_train_test(df):\n",
    "    predictor = df['ack'].copy()\n",
    "    independants = df.drop('ack', axis=1).copy()\n",
    "    independants_train, independants_test, predictor_train, predictor_test = train_test_split(independants, predictor,\n",
    "                                                                                              test_size=0.2,\n",
    "                                                                                              random_state=42)\n",
    "    predictor_train = predictor_train.reset_index().drop('index', axis=1)\n",
    "    predictor_test = predictor_test.reset_index().drop('index', axis=1)\n",
    "    independants_train = independants_train.reset_index().drop('index', axis=1)\n",
    "    independants_test = independants_test.reset_index().drop('index', axis=1)\n",
    "    return [predictor_train, predictor_test, independants_train, independants_test]\n",
    "\n",
    "\n",
    "mnoziny = split_train_test(df_merged)\n",
    "predictor_train, predictor_test, independants_train, independants_test = mnoziny[0], mnoziny[1], mnoziny[2], mnoziny[3]\n",
    "\n",
    "\n",
    "class ToIntTransformations(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X['session_start'] = X['session_start'].apply(to_seconds_since_epoch)\n",
    "        X['registration'] = X['registration'].apply(to_int_from_registration)\n",
    "        return X\n",
    "\n",
    "\n",
    "class HighNanDropPlusUselessColDeletion(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, percentage):\n",
    "        self.percentage = percentage\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        ratio = int(((100 - self.percentage) / 100) * X.shape[0] + 1)\n",
    "        nan_percentage = X.isna().mean() * 100\n",
    "        print(\"deleted rows:\\n\", nan_percentage[nan_percentage > 30])\n",
    "        X = X.dropna(axis=1, thresh=ratio)\n",
    "        X = X.drop(\n",
    "            columns=['session_id', 'user_id', 'product_ean', 'name', 'username', 'address', 'mail', 'current_location'],\n",
    "            axis=1)\n",
    "        return X\n",
    "\n",
    "\n",
    "class NanRemover(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.dropna()\n",
    "        return X\n",
    "\n",
    "\n",
    "class NanReplacerBoth(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = replace_missing_All(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "class RemoveOutliers(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = remove_outliers_for_num_column(X, 0.02, 0.98)\n",
    "        return X\n",
    "\n",
    "\n",
    "class ReplaceOutliers(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = replace_outliers_for_num_column(X, 0.02, 0.98)\n",
    "        return X\n",
    "\n",
    "\n",
    "class BoxCoxTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.lambdas_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.lambdas_ = []\n",
    "        for column in X:\n",
    "            _, lambda_ = stats.boxcox(X[column] + abs(X[column].min()) + 1)\n",
    "            self.lambdas_.append(lambda_)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transformed_X = X.copy()\n",
    "        for column, lambda_ in enumerate(self.lambdas_):\n",
    "            transformed_X.iloc[:, column] = stats.boxcox(X.iloc[:, column] + abs(X.iloc[:, column].min()) + 1,\n",
    "                                                         lmbda=lambda_)\n",
    "\n",
    "        return transformed_X\n",
    "\n",
    "\n",
    "class PowPointTwoTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transforemed_X = X.copy()\n",
    "        for column in transforemed_X:\n",
    "            transforemed_X[column] = pd.DataFrame((X[column]) ** (1 / 1.2))\n",
    "        return transforemed_X\n",
    "\n",
    "\n",
    "class StandardScalerMine(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        holder = X.copy()\n",
    "        X = self.scaler.transform(X)\n",
    "        X = pd.DataFrame(X, columns=holder.columns)\n",
    "        return X\n",
    "\n",
    "\n",
    "class MinMaxScalerMine(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        holder = X.copy()\n",
    "        X = self.scaler.transform(X)\n",
    "        X = pd.DataFrame(X, columns=holder.columns)\n",
    "        return X\n",
    "\n",
    "\n",
    "class RobusScalerMine(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = RobustScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        holder = X.copy()\n",
    "        X = self.scaler.transform(X)\n",
    "        X = pd.DataFrame(X, columns=holder.columns)\n",
    "        return X\n",
    "\n",
    "\n",
    "class OneHotEncoderMine(BaseEstimator, TransformerMixin):\n",
    "    #enkodovanie kategorickych dat pomocou OneHotEncoder ktory rozdeli kazdu kategoriu stlpca na vlastny stlpec, \n",
    "    #ktory bude mat hodntou 1 tam kde bola hodnota v originalnom stlpci a 0 na zvysku\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        result = pd.DataFrame(columns=['a'])\n",
    "        x = 0\n",
    "        for column in X:\n",
    "            encoder = OneHotEncoder()\n",
    "            transform = encoder.fit_transform(X[[column]]).toarray()\n",
    "            categories = encoder.categories_\n",
    "            categories = np.array(categories).ravel()\n",
    "            if x == 1:\n",
    "                categories += '_W'\n",
    "            elif x == 2:\n",
    "                categories += '_H'\n",
    "            temp_df = pd.DataFrame(transform, columns=categories)\n",
    "            result = pd.concat([result, temp_df], axis=1)\n",
    "            x += 1\n",
    "        return result.drop('a', axis=1)\n",
    "\n",
    "\n",
    "#touto pipline si prechadzaju vsetky data su v nej zakladne transformacie na zlepsie formatu dataframu\n",
    "pipeline_pre_encoding_transforming = Pipeline([\n",
    "    ('highdropper', HighNanDropPlusUselessColDeletion(30)),\n",
    "    ('tointtrans', ToIntTransformations()),\n",
    "    ('NanSolution', NanReplacerBoth())\n",
    "])\n",
    "\n",
    "#pipeline pre numericke data\n",
    "pipeline_num_transforming = Pipeline([\n",
    "    ('outlierhandling', ReplaceOutliers()),\n",
    "    ('transformer', PowPointTwoTransformer()),\n",
    "    ('scaler', RobusScalerMine())\n",
    "])\n",
    "\n",
    "# pipeline pre kategoricke data\n",
    "pipeline_categ_transforming = Pipeline([\n",
    "    ('encoder', OneHotEncoderMine())\n",
    "])\n",
    "\n",
    "#inicialna pipeline len na pripravenie dat na transformovanie\n",
    "pre_trans_encode_All = pipeline_pre_encoding_transforming.fit_transform(df_merged)\n",
    "\n",
    "# rozdelenie na trian a test susety\n",
    "mnoziny = split_train_test(pre_trans_encode_All)\n",
    "predictor_train, predictor_test, independants_train, independants_test = mnoziny[0], mnoziny[1], mnoziny[2], mnoziny[3]\n",
    "\n",
    "\n",
    "# column_transformer pre paralelne spracovanie\n",
    "# column_transformer = ColumnTransformer([\n",
    "#     ('numerical', pipeline_num_transforming, independants_train.select_dtypes(include='number').columns),\n",
    "#     ('categorical', pipeline_categ_transforming, independants_train.select_dtypes(exclude='number').columns)\n",
    "# ])\n",
    "\n",
    "# # vysledok nie je vo forme data frame preto bola vytvorena funkcia scaling\n",
    "# col_trans = column_transformer.fit_transform(independants_train)\n",
    "\n",
    "\n",
    "def scaling_train(df, ack_df):\n",
    "    nums_scaled_transformed = pipeline_num_transforming.fit_transform(df.select_dtypes(include='number'))\n",
    "    cats_scaled_tranformed = pipeline_categ_transforming.fit_transform(df.select_dtypes(exclude='number'))\n",
    "    # pouziva sa dropna pri returne pretoze pri pouziti remove ourliers na numerickych datach sa nasledne pri concate vytvorili NaN kedze remove outliers nebol pouzity na kategoricke data\n",
    "    # toto nie je problem pri rieseni outlierov pomocou nahradzovania\n",
    "    return pd.concat([nums_scaled_transformed, cats_scaled_tranformed, ack_df], axis=1).dropna()\n",
    "\n",
    "\n",
    "def scaling_test(df, ack_df):\n",
    "    nums_scaled_transformed = pipeline_num_transforming.transform(df.select_dtypes(include='number'))\n",
    "    cats_scaled_tranformed = pipeline_categ_transforming.transform(df.select_dtypes(exclude='number'))\n",
    "    # pouziva sa dropna pri returne pretoze pri pouziti remove ourliers na numerickych datach sa nasledne pri concate vytvorili NaN kedze remove outliers nebol pouzity na kategoricke data\n",
    "    # toto nie je problem pri rieseni outlierov pomocou nahradzovania\n",
    "    return pd.concat([nums_scaled_transformed, cats_scaled_tranformed, ack_df], axis=1).dropna()\n",
    "\n",
    "\n",
    "final_frame_train = scaling_train(independants_train, predictor_train)\n",
    "final_frame_test = scaling_test(independants_test, predictor_test)\n",
    "\n",
    "K_best_classif(final_frame_train.drop('ack', axis=1), final_frame_train['ack'], 10)\n",
    "print('-------------------')\n",
    "corr_best(final_frame_train, 10)\n",
    "\n",
    "K_best_classif(final_frame_test.drop('ack', axis=1), final_frame_test['ack'], 10)\n",
    "print('-------------------')\n",
    "corr_best(final_frame_test, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vysledok feature selection\n",
    "- vysledky su zoradene podla atributov s najlepsim skore cize nalepsi potencial na predikovanie ack\n",
    "- z vysledku vieme nasledne vybrat x atributov na nasledne trenovanie ML modelu\n",
    "- pocet vybranych atributov sa moze lubovolne menit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50 / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "..  ..\n",
      "810  0\n",
      "811  0\n",
      "812  1\n",
      "813  1\n",
      "814  1\n",
      "\n",
      "[815 rows x 1 columns] 0      0.0\n",
      "1      0.0\n",
      "2      1.0\n",
      "3      1.0\n",
      "4      0.0\n",
      "      ... \n",
      "810    1.0\n",
      "811    0.0\n",
      "812    1.0\n",
      "813    1.0\n",
      "814    1.0\n",
      "Name: ack, Length: 815, dtype: float64\n",
      "Accuracy:  0.7325153374233129\n",
      "Precision:  0.777511961722488\n",
      "Recall:  0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "temp_df = independants_train\n",
    "temp_df['ack'] = predictor_train\n",
    "test_df = independants_test\n",
    "test_df['ack'] = predictor_test\n",
    "\n",
    "class OneRClassif:\n",
    "    def __init__(self, max_depth=1) -> None:\n",
    "        self.rules = dict()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.best_column = None\n",
    "        self.lowest_error = 1\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X):\n",
    "        length_df = len(X)\n",
    "        check_len = length_df\n",
    "        teoretic_MAX = 0\n",
    "        while check_len > 10:\n",
    "            check_len /= 10\n",
    "            teoretic_MAX += 1\n",
    "        if self.max_depth == teoretic_MAX:\n",
    "            print(f\"cannot fit data because length of set doesnt allow depth of {self.max_depth} changing max depth to {teoretic_MAX - 1}\")\n",
    "            self.max_depth = teoretic_MAX - 1\n",
    "\n",
    "        for column in X:\n",
    "            if column == 'ack':\n",
    "                continue\n",
    "            df = X[[column, 'ack']]\n",
    "            if pd.api.types.is_numeric_dtype(X[column]):  # is numeric column\n",
    "                df = df.sort_values(by=column, ascending=True).reset_index()\n",
    "                # rozdelenie na 10 rangeov\n",
    "                part_size = length_df // 10\n",
    "                ranges = {}\n",
    "                total_error_rate = 0\n",
    "\n",
    "                for i in range(10):\n",
    "                    start_index = i * part_size\n",
    "                    end_index = start_index + part_size if i < 9 else length_df\n",
    "\n",
    "                    majority = self.find_majority(df[start_index: end_index])\n",
    "                    if start_index == 0:\n",
    "                        ranges[(np.finfo(np.float64).min, df[column][end_index])] = majority[0]\n",
    "                    elif i == 9:\n",
    "                        ranges[(df[column][start_index], np.finfo(np.float64).max )] = majority[0]\n",
    "                    else:\n",
    "                        ranges[(df[column][start_index], df[column][end_index])] = majority[0]\n",
    "                    total_error_rate += majority[1] / length_df\n",
    "                if total_error_rate < self.lowest_error:\n",
    "                    self.lowest_error = total_error_rate\n",
    "                    self.best_column = column\n",
    "                    self.rules = ranges\n",
    "            else:\n",
    "                # df[column] = self.label_encoder.fit_transform(df[column]) nefunguje to aj tak\n",
    "                pd.options.mode.chained_assignment = None\n",
    "                df[column] = df[column].astype('category')\n",
    "                unique_cats = df[column].cat.categories\n",
    "                categories = {}\n",
    "                total_error_rate = 0\n",
    "                for category in unique_cats:\n",
    "                    majority = self.find_majority(df[df[column] == category])\n",
    "                    total_error_rate += majority[1] / length_df\n",
    "                    categories[(category,)] = majority[0]\n",
    "                if total_error_rate < self.lowest_error:\n",
    "                    self.lowest_error = total_error_rate\n",
    "                    self.best_column = column\n",
    "                    self.rules = categories\n",
    "        self.rules[\"name\"] = self.best_column\n",
    "        if self.max_depth > 0:\n",
    "            # print(self.rules)\n",
    "            for key in self.rules.keys():\n",
    "                if key == \"name\":\n",
    "                    continue\n",
    "                if pd.api.types.is_numeric_dtype(X[self.best_column]):\n",
    "                    new_OneR = OneRClassif(self.max_depth - 1)\n",
    "                    new_OneR = new_OneR.fit(X[(key[0] <= X[self.best_column]) & (key[1] >= X[self.best_column])])\n",
    "                    self.rules[key] = new_OneR.rules\n",
    "                else:\n",
    "                    new_OneR = OneRClassif(self.max_depth - 1)\n",
    "                    new_OneR = new_OneR.fit(X[X[self.best_column] == key])\n",
    "                    self.rules[key] = new_OneR.rules\n",
    "        return self\n",
    "\n",
    "    def find_majority(self, df):\n",
    "        yes = df['ack'].sum()\n",
    "        no = len(df) - yes\n",
    "        if yes > no:\n",
    "            return 1, no\n",
    "        else:\n",
    "            return 0, yes\n",
    "\n",
    "    def predict(self, X):\n",
    "        value = X[self.rules['name']]\n",
    "        current_rules = self.rules\n",
    "        while True:\n",
    "            if pd.api.types.is_numeric_dtype(value):\n",
    "                for key in current_rules:\n",
    "                    if key[0] <= value <= key[1]:\n",
    "                        current_rules = current_rules[key]\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                for key in current_rules:\n",
    "                    if key == value:\n",
    "                        current_rules = current_rules[key]\n",
    "                        break\n",
    "            if current_rules in [0,1]:\n",
    "                return current_rules\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "newOne = OneRClassif(max_depth=0)\n",
    "newOne.fit(temp_df)\n",
    "result = []\n",
    "correct = 0\n",
    "true_pos  = 0\n",
    "true_negative = 0\n",
    "false_pos = 0\n",
    "false_negative = 0\n",
    "for i in range(len(test_df)):\n",
    "        result.append(newOne.predict(test_df.iloc[i]))\n",
    "        if result[-1] == 1 and test_df[\"ack\"].iloc[i] == 1:\n",
    "            true_pos += 1\n",
    "        elif result[-1] == 1 and test_df[\"ack\"].iloc[i] == 0:\n",
    "            false_pos += 1\n",
    "        elif result[-1] == 0 and test_df[\"ack\"].iloc[i] == 0:\n",
    "            true_negative += 1\n",
    "        elif result[-1] == 0 and test_df[\"ack\"].iloc[i] == 1:\n",
    "            false_negative += 1\n",
    "result_frame = pd.DataFrame(result)\n",
    "print(result_frame, test_df[\"ack\"])\n",
    "print(\"Accuracy: \",(true_pos + true_negative) / (true_pos + true_negative + false_pos + false_negative))\n",
    "print(\"Precision: \", true_pos / (true_pos + false_pos))\n",
    "print(\"Recall: \", true_pos / (true_pos + false_negative))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
